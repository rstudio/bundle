---
title: "Getting started with bundle"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting started with bundle}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
should_eval <- rlang::is_installed("lightgbm") && rlang::is_installed("callr")

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = should_eval
)
```

R holds most objects in memory. However, some models store their data in locations that are not included when one uses `save()` or `saveRDS()`. bundle provides a common API to capture this information, situate it within a portable object, and restore it for use in new settings.

This vignette will walk through a common use case for bundling---storing a statistical model to deploy in production---to showcase the benefits of the package.

```{r setup}
library(bundle)
```

In addition to the package itself, we'll load the lightgbm package to fit some example models, and the callr package to generate fresh R sessions to test our models inside of.

```{r setup-exts}
library(lightgbm)
library(callr)
```

## Where `save()` and `load()` fall short

As an example, let's fit a simple model with the lightgbm package, modeling miles per gallon using the rest of the variables in the built-in `mtcars` dataset.

```{r mtcars-fit}
cars_train <- 
  lgb.Dataset(
    data = as.matrix(mtcars[1:25, 2:ncol(mtcars)]), 
    label = mtcars[1:25, 1],
    params = list(feature_pre_filter = "false")
  )

cars_test <- as.matrix(mtcars[26:32, 2:ncol(mtcars)])

lgb_fit <-
  lgb.train(
    params = list(
      max_depth = 3, 
      min_data_in_leaf = 5, 
      objective = "regression"
    ), 
    data = cars_train, 
    nrounds = 5,
    verbose = -1
  )
```

Easy peasy! Now, given that this model is trained, we assume that it's ready to go to predict on new data. Our mental map might look something like this:

```{r diagram-01, echo = FALSE, fig.alt = "A diagram showing a rectangle, labeled model object, and another rectangle, labeled predictions. The two are connected by an arrow from model object to predictions, with the label predict."}
knitr::include_graphics("man/figures/diagram_01.png")
```

We pass a model object to the `predict()` function, along with some new data to predict on, and get predictions back. Straightforward enough--- let's try it out:

```{r}
predict(lgb_fit, cars_test)
```

Perfect.

If we're satisfied with this model and think it provides some valuable insights, we might want to deploy it somewhere---maybe on a Shiny app---so that others can make use of it.

The callr package will be helpful for emulating this kind of situation. The package allows us to start up a fresh R session and pass a few objects in. 

We'll just make use of two of the arguments to the function `r()`: `func`, which we'll supply the code we want to run in, and `args`, which we'll pass our model objects to. 

As an example:

```{r}
r(
  function(x) {
    x * 2
  },
  args = list(
    x = 1
  )
)
```

So, our approach might be:

* save our model object
* start up a new R session
* load the model object into the new session
* predict on new data with the loaded model object

First, saving our model object to file:

```{r}
temp_file <- tempfile()

saveRDS(lgb_fit, file = temp_file)
```

Now, starting up a fresh R session and predicting on new data:

```{r}
r(
  function(temp_file) {
    library(lightgbm)
    
    model_object <- readRDS(file = temp_file)
    
    new_data <- as.matrix(mtcars[26:32, 2:ncol(mtcars)])
    
    predict(model_object, new_data)
  },
  args = list(
    temp_file = temp_file
  )
)
```

Oof. This error is a bit much. It _does_ seem to point us to something helpful, though: the lightgbm package provides its own functions to save lightgbm objects. 

Given this new understanding, we can update our mental map a bit. Some objects require extra information when they're loaded into new environments in order to do their thing. In this case, this lightgbm model object needs access to a Booster instance in order to predict on new data. This "extra information."

```{r diagram-02, echo = FALSE, fig.alt = "A diagram showing the same pair of rectangles as before, connected by the arrow labeled predict. This time, though, we introduce two boxes labeled reference. These two boxes are connected to the arrow labeled predict with dotted arrows, to show that, most of the time, we don't need to think about including them in our workflow."}
knitr::include_graphics("man/figures/diagram_02.png")
```
In computer science, these bits of "extra information" are called _references_. Those references need to persist---or be restored---in new environments in order for the objects that reference them to work well.

These kinds of custom methods to save objects, like the ones that lightgbm provide, are often referred to as _native serialization_. Methods for native serialization know which references need to be brought along in order for an object to effectively do it's thing in a new environment.

Let's make use of native serialization, then!

## Where native serialization falls short

lightgbm's error was really informative in telling us what we ought to do from here---if we save the model with their native serialization rather than `saveRDS`, we'll be good to go.

Saving our model object with their methods:

```{r}
saveRDS.lgb.Booster(lgb_fit, file = temp_file)
```

Now, starting up a fresh R session and predicting on new data:

```{r}
r(
  function(temp_file) {
    library(lightgbm)
    
    model_object <- readRDS.lgb.Booster(file = temp_file)
    
    new_data <- as.matrix(mtcars[26:32, 2:ncol(mtcars)])
    
    predict(model_object, new_data)
  },
  args = list(
    temp_file = temp_file
  )
)
```

Awesome! Making use of their methods, we were able to effectively save our model, load it in a new R session, and predict on new data.

Now, a new scenario---I've heard that xgboost models are super performant, and want to try to productionize those, too. How would we do that?

Based on our workflow just now, we could try to just save it with `saveRDS` and see if we get an informative error somewhere along the way to predicting in a new R session. Or, maybe a better approach would be to read through their documentation and see if we can find anything related to serialization. 

We've done the work of figuring that out, and it turns out the interface is a little bit different. You'll need to make sure the parameters object persists across sessions, but `saveRDS` will work by itself if... ah, nevermind.

What if we could just use the same function for any R object, and it would _just work_?

```{r diagram-03, echo = FALSE, fig.alt = "A diagram showing the same set of rectangles, representing a prediction problem, as before. This version of the diagram adds two boxes, labeled R Session numbe r one, and R session number two. In R session number two, we have a new rectangle labeled standalone model object. In focus is the arrow from the model object, in R Session number one, to the standalone model object in R session number two."}
knitr::include_graphics("man/figures/diagram_03.png")
```

## Using bundle

bundle provides a consistent interface to save and load R objects. The package provides two functions---`bundle()` and `unbundle()`---that take care of all of the minutae of saving and loading R objects effectively.

```{r diagram-04, echo = FALSE, fig.alt = "A replica of the previous diagram, where the arrow previously connecting the model object in R session one and the standalone model object in R session two is connected by a verb called bundle. The bundle function outputs an object called a buncle."}
knitr::include_graphics("man/figures/diagram_04.png")
```


Bundles are just lists with two elements:

* `object`: The `object` element of a bundle is the serialized version of the inputted object. In the simplest situations in modeling, this object is just the output of a native serialization function like `saveRDS.lgb.Booster` that we used earlier.
* `situate()`: The `situate()` element of a bundle is a function that _situates_ the `object` element in its new environment. It takes in the `object` element as input, but also "freezes" reference that existed when the original object was created.

When `unbundle()` is called on a bundle object, the `situate()` element of the bundle will re-load the `object` element and restore needed references in the new environment. Thus, the output of `unbundle()` is ready to go for whatever tasks it'd be used for in the original environment.

To be a bit more concrete, lets return to the lightgbm example.

```{r}
lgb_bundle <- bundle(lgb_fit)
```

Now, starting up a fresh R session and predicting on new data:

```{r}
r(
  function(model_bundle) {
    library(bundle)
    
    model_object <- unbundle(model_bundle)
    
    new_data <- as.matrix(mtcars[26:32, 2:ncol(mtcars)])
    
    predict(model_object, new_data)
  },
  args = list(
    model_bundle = lgb_bundle
  )
)
```

Huzzah!

The best part is, if you wanted to do the same thing for an xgboost object, you could use the same code!

First, fitting a quick xgboost model:

```{r}
xgb_fit <- 
  xgboost(
    data = as.matrix(mtcars[1:25, 2:ncol(mtcars)]), 
    label =  mtcars[1:25, 1],
    nrounds = 5
  )
```

Now, bundling it: 

```{r}
xgb_bundle <- bundle(xgb_fit)
```

Now, starting up a fresh R session and predicting on new data:

```{r}
r(
  function(model_bundle) {
    library(bundle)
    
    model_object <- unbundle(model_bundle)
    
    new_data <- as.matrix(mtcars[26:32, 2:ncol(mtcars)])
    
    predict(model_object, new_data)
  },
  args = list(
    model_bundle = xgb_bundle
  )
)
```

VoilÃ ! We hope bundles make your modeling and deployment workflows a good bit smoother in the future.
